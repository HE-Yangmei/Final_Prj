{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HE-Yangmei/Final_Prj/blob/master/cnn/transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NNOQQ2XldFFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 04图像风格迁移"
      ]
    },
    {
      "metadata": {
        "id": "1YMsx5d7dFF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## !pip install scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQrDfF5troA-",
        "colab_type": "code",
        "outputId": "3edccda6-4892-4d0d-e58c-1e3c397e6f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131323 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xuK20jWvsihq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "03P1QQP6s9h1",
        "colab_type": "code",
        "outputId": "53a6b873-9254-4691-ac73-1836432db36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZznJymZ1sq-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/Colab_Notebooks\") \n",
        "os.chdir(\"final_prj/CNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhw2TB_NdFGh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## 修改环境变量\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='tensorflow'\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from scipy.misc import imsave\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "## 拟牛顿最优化\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9WGNOXQdFHD",
        "colab_type": "code",
        "outputId": "397fe0af-7a8f-4ab9-eaef-bda7335deaec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='Neural style transfer with Tensorflow.')\n",
        "parser.add_argument('base_image_path', metavar='base', type=str,\n",
        "                    help='Path to the image to transform.')\n",
        "parser.add_argument('style_reference_image_path', metavar='ref', type=str,\n",
        "                    help='Path to the style reference image.')\n",
        "parser.add_argument('result_prefix', metavar='res_prefix', type=str,\n",
        "                    help='Prefix for the saved results.')\n",
        "parser.add_argument('--iter', type=int, default=10, required=False,\n",
        "                    help='Number of iterations to run.')\n",
        "parser.add_argument('--content_weight', type=float, default=0.025, required=False,\n",
        "                    help='Content weight.')\n",
        "parser.add_argument('--style_weight', type=float, default=1.0, required=False,\n",
        "                    help='Style weight.')\n",
        "parser.add_argument('--tv_weight', type=float, default=1.0, required=False,\n",
        "                    help='Total Variation weight.')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--tv_weight'], dest='tv_weight', nargs=None, const=None, default=1.0, type=<class 'float'>, choices=None, help='Total Variation weight.', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "WtIxAuD1KcqI",
        "colab_type": "code",
        "outputId": "45073411-3d20-45de-844f-03fa50fda219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "style  transfer.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0L0gtdnpdFHi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args = parser.parse_args([r'content/y_rose.jpg', \n",
        "                         'style/rose.jpg', \n",
        "                         'rose_'])\n",
        "base_image_path = args.base_image_path\n",
        "style_reference_image_path = args.style_reference_image_path\n",
        "result_prefix = args.result_prefix\n",
        "iterations = args.iter\n",
        "\n",
        "total_variation_weight = args.tv_weight\n",
        "style_weight = args.style_weight\n",
        "content_weight = args.content_weight\n",
        "\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nO-gO_wqdFH5",
        "colab_type": "code",
        "outputId": "3f8bb06a-ab90-4718-a60c-b62b7dd569dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size = (img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.reshape((3, img_nrows, img_cols))\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    else:\n",
        "        x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image\n",
        "                                  (style_reference_image_path))\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
        "else:\n",
        "    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
        "    \n",
        "input_tensor = K.concatenate([base_image, \n",
        "                             style_reference_image, \n",
        "                             combination_image], axis = 0)\n",
        "\n",
        "model = vgg19.VGG19(input_tensor = input_tensor, \n",
        "                   weights = \"imagenet\", include_top = False)\n",
        "print('Model Loaded')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cIbEkAeIdFIT",
        "colab_type": "code",
        "outputId": "1b99446d-a01a-474e-dfd9-741ca89efe6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "cell_type": "code",
      "source": [
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "## 效用函数\n",
        "def gram_matrix(x):\n",
        "    assert K.ndim(x) == 3\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        features = K.batch_flatten(x)\n",
        "    else:\n",
        "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n",
        "\n",
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
        "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
        "    else:\n",
        "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "## 标量\n",
        "loss = K.variable(0.)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss += content_weight * content_loss(base_image_features, \n",
        "                                     combination_features)\n",
        "features_layers = ['block1_conv1', 'block2_conv1', \n",
        "                  'block3_conv1', 'block4_conv1', \n",
        "                  'block5_conv1']\n",
        "for layer_name in features_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    s1 = style_loss(style_reference_features, combination_features)\n",
        "    loss += (style_weight / len(features_layers)) * s1\n",
        "loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "\n",
        "## 梯度\n",
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
        "    else:\n",
        "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "class Evaluator(object):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "        \n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "    \n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values\n",
        "    \n",
        "evaluator = Evaluator()\n",
        "\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), \n",
        "                                    fprime = evaluator.grads, maxfun = 20)\n",
        "    print('Current loss value:', min_val)\n",
        "    \n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix + '_%d.png' % i\n",
        "    imsave(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed  in %ds' % (i, end_time - start_time))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "Start of iteration 0\n",
            "Current loss value: 2277602800.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:110: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image saved as rose__at_iteration_0.png\n",
            "Iteration 0 completed  in 24s\n",
            "Start of iteration 1\n",
            "Current loss value: 1584615200.0\n",
            "Image saved as rose__at_iteration_1.png\n",
            "Iteration 1 completed  in 19s\n",
            "Start of iteration 2\n",
            "Current loss value: 1391573400.0\n",
            "Image saved as rose__at_iteration_2.png\n",
            "Iteration 2 completed  in 20s\n",
            "Start of iteration 3\n",
            "Current loss value: 1294483200.0\n",
            "Image saved as rose__at_iteration_3.png\n",
            "Iteration 3 completed  in 19s\n",
            "Start of iteration 4\n",
            "Current loss value: 1222144300.0\n",
            "Image saved as rose__at_iteration_4.png\n",
            "Iteration 4 completed  in 20s\n",
            "Start of iteration 5\n",
            "Current loss value: 1178116600.0\n",
            "Image saved as rose__at_iteration_5.png\n",
            "Iteration 5 completed  in 20s\n",
            "Start of iteration 6\n",
            "Current loss value: 1145241300.0\n",
            "Image saved as rose__at_iteration_6.png\n",
            "Iteration 6 completed  in 19s\n",
            "Start of iteration 7\n",
            "Current loss value: 1119529600.0\n",
            "Image saved as rose__at_iteration_7.png\n",
            "Iteration 7 completed  in 19s\n",
            "Start of iteration 8\n",
            "Current loss value: 1096263700.0\n",
            "Image saved as rose__at_iteration_8.png\n",
            "Iteration 8 completed  in 20s\n",
            "Start of iteration 9\n",
            "Current loss value: 1076975400.0\n",
            "Image saved as rose__at_iteration_9.png\n",
            "Iteration 9 completed  in 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qeLDUYnI3MVL",
        "colab_type": "code",
        "outputId": "ab7b9ab6-fd11-479a-d529-6436e531f069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "tensorboard --logdir=samples_starry"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-4372eac4f2e4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=samples_starry\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    }
  ]
}